{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 로지스틱 회귀"
   ]
  },
  {
   "attachments": {
    "p.328.PNG": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHgAAAA/CAYAAAArOQwGAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAEnQAABJ0Ad5mH3gAAAS3SURBVHhe7ZxfSFtXHMcHvvjsi+BrwceJLz5uPsy9tIE9FJxP7m0bwjbY0xiCdSvtg2Uw4ro/DKRC5sMsNgQ2BQld09I46nSjQrYa7YZt2nGxpg2JMfG7+03vSW9Cbrz3LrU3p78P/DDenBvC/eSc8zt/7n0FgtaIYM0RwZojgjVHBGuOCNYcEaw5IlhzRLDmiGDNEcGaI4J9kEwmMTo6CsMwrCPBRQR7IBKJYGJiAiMjI+jp6cHOzo71TnARwR6YnJxEKBTCwMCACNaZaDQqgnVGBGuOCNYcEaw5IlhzRLDmiGDNEcGaI4I1hXPQlDs+Po6uri7MzMxU/k+lUlaJ4CGCPcAFBtbc+piamrJKBA8R7AGuHrFZro9sNmuVCB4iWHNEsOY0FZzJZCpJBIOvFfl8HktLSzXH7DDpUOd5CafPE/zjKJj9ytzcHLq7u9HR0VERoGC/w+TCfswOk476RMRN8EcjtBZHwZQ0PDyM1dXVimQvgvnjsCchboMtg9BaHAWzmeW4jxfeLpPHKJ61+/ia1B1sJSO4EArhtBncVSFhj9NmXEAkuWVeqVqa9sGUzD1IDDWYp2gKp3gn4vF49Twv4TxhYCCTimPeLHO27hwJxlkz5hFPZcwrVUtTwY1kuhHMzWmNf2nNg62D0Fo8CVaJV39/v2S8bYInwSrxotxSqVQ5JgSbpoIpkjWWUtmE9vb2Vv4K7UNTwYTNMmsuO/PBwUER3GY4ClbDJAVfUzI3fwvHRLkI/LuBjd/+xJ27/+BhJo3fF1dwx9hHzmUP6SiYMoeGhir9L4PNdJCXxfTjEIcFA4XlCZx57xy++H4WsehFfPLqO7j4q4G7OavYETQV3NnZWUmyGOyLg7wsph85FAqbSCyvY3N+FpcvzeLrKzfw6L6Bx/tllA6tYkfQtIlmFq0i6MMidh0cf/uF5z6P7qeU30Nm8TN8OjZSHe/Xxkf4eDKGdbOs2SA/I/8ExXtp3H6Qxd71bxFduIxw4pH1pnuOTLKCjH2mjRk+//qF5/KCt5ryfg67t37AzPT56netjW/wXWQFabPswdNTnlIsory7i91yGdsLYcRiUSxsPztW82NoQlsLZuKnagIXRHjB/MJzn4dgvxRyZs3f/gNb2fu4cv4rLPy4iFt7T/Dg9hbuFQ/gdlmmrQXboRydBD9MryE2/T7OxS/hg3e/xPT0Mq5uGria+Nvsm91PMolgi6AJfpy+jmufv44TJ97EqZNv4LW3P8RbZ37GX6bcA5cJFhHBFv9HcP3iSisWTUo5A0YqgcWfErh5M4FfVtZxYyNj5tYcQLnnpROsHsNQH5ylU4lafXD87zREdPo8LpkGgZdOsHoMQ31QLhO1Ru81euCK2pc2NjZWHZ41OvaikSbagufyM9zC2T1OAPHuBjXbt7a2hr6+vkDtLRPBFn4F8xYWNdtHuZQcpL1lItjCr2Dep6Rm+1hzg7ZxUARb+BVMsfWw/5UkqwVwflzVHj67ig8o81uTvApm0sXkKxwOV7+DCkmyWgRFqv7PHn72jHEoRGFeaXTHoSRZLYK1VGWw9vCzZ4zjXD/Pnmx0x6EkWcKxIYI1RwRrjgjWHBGsOSJYc0Sw1gD/AftSP37Nr7XmAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로지스틱 회귀는 선형 회귀 방식을 분류에 적용한 알고리즘이다. 회귀가 선형인지, 비선형인지는 가중치 변수가 선형인지 아닌지를 따른다. 로지스틱 회귀가 선형 회귀와 다른 점은 <u>**시그모이드 함수**</u> 최적선을 찾고, 이 시그모이드 함수의 반환 값을 확률로 간주해 확률에 따라 분류를 결정한다.  \n",
    "\n",
    "\n",
    "**시그모이드(Sigmoid) 함수**  \n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/8/88/Logistic-curve.svg' width=\"450\" height=\"450\">\n",
    "\n",
    "![p.328.PNG](attachment:p.328.PNG)\n",
    "\n",
    "- x 값이 +,-로 아무리 커지거나 작아져도 y 값은 항상 0과 1사이 값을 반환한다.  \n",
    "- x 값이 커지면 1에 근사하여 x 값이 작아지면 0에 근사한다. 그리고 x가 0일 때는 0.5이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 종양 크기에 따라 악성 종양인지(Yes=1) 그렇지 않은지(No=0)를 회귀를 이용해 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://blog.kakaocdn.net/dn/OLFGf/btqCvzeKcZq/avF9KCl0GRHlJ6G8Vq4UEK/img.png' width=\"600\" height=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 학습 데이터 세트와 테스트 데이터 세트로 나눔\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# StandardScaler( )로 평균이 0, 분산 1로 데이터 분포도 변환\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(cancer.data)\n",
    "\n",
    "X_train , X_test, y_train , y_test = train_test_split(data_scaled, cancer.target, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.977\n",
      "roc_auc: 0.972\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# 로지스틱 회귀를 이용하여 학습 및 예측 수행. \n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_preds = lr_clf.predict(X_test)\n",
    "\n",
    "# accuracy와 roc_auc 측정\n",
    "print('accuracy: {:0.3f}'.format(accuracy_score(y_test, lr_preds)))\n",
    "print('roc_auc: {:0.3f}'.format(roc_auc_score(y_test , lr_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 하이퍼 파라미터:{'C': 1, 'penalty': 'l2'}, 최적 평균 정확도:0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dldms\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "## GridSearchCV를 이용해 위스콘신 데이터 세트에서 하이퍼 파라미터를 최적화\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 주요 하이퍼 파라미터\n",
    "params={'penalty':['l2', 'l1'],        # l2 : L2 규제, l1 : L1 규제\n",
    "        'C':[0.01, 0.1, 1, 1, 5, 10]} # C : 규제 강도를 조절하는 alpha값의 역수 \n",
    "                                     # C값이 작을수록 규제 강도가 크다\n",
    "\n",
    "grid_clf = GridSearchCV(lr_clf, param_grid=params, scoring='accuracy', cv=3 )\n",
    "grid_clf.fit(data_scaled, cancer.target)\n",
    "print('최적 하이퍼 파라미터:{0}, 최적 평균 정확도:{1:.3f}'.format(grid_clf.best_params_, grid_clf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
